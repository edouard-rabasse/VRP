# Optimized VRP Iterative Pipeline

This repository contains an optimized iterative pipeline that combines PyTorch-based arc flagging with Vehicle Routing Problem (VRP) solving. The main improvement is that the PyTorch model is loaded once and reused across iterations, signntly improving performance.

## Files Overview

### Core Pipeline Files

- `iterative_solver.py` - Main optimized pipeline class
- `train.py` - Function to train your computer vision model
- `visualize.py` - Function to see the output of your matrix.

- `run_vrp_solver.sh` - Shell script to run iterative VRP solver

### Java VRP Solver Integration

- `MSH/MSH/src/split/SplitWithEdgeConstraints.java` - Modified with custom cost calculation
- `MSH/MSH/src/distanceMatrices/CustomArcCostMatrix.java` - Custom cost storage
- `MSH/MSH/src/pulseStructures/PulseHandlerCC.java` - Pulse algorithm with custom costs

## Project Structure

### Core Modules

#### `src/models/` - Neural Network Models

- **Purpose**: PyTorch models for VRP image classification and segmentation
- **Key Files**:
  - `resnet.py` - ResNet-based classifier for arc scoring
  - `vgg_segment.py` - VGG model with segmentation head
  - `__init__.py` - Model factory and loading utilities
- **Usage**: Loaded once per pipeline run, reused across iterations

#### `src/trainers/` - Model Training

- **Purpose**: Training routines for VRP models
- **Key Files**:
  - `__init__.py` - Trainer factory and utilities
  
#### `src/visualization/` - Heatmap Generation

- **Purpose**: Generate and visualize heatmaps for model predictions. This is only used to visualize the heatmaps but the main script doesn't rely on this.
- **Key Files**:
  - `get_heatmap.py` - File where all the different heatmap methods are implemented
  - `save_overlay.py` - Saves overlay images of heatmaps on original images

- **Purpose**: Generate and overlay attention heatmaps on VRP instances
- **Key Files**:
  - `get_heatmap.py` - GradCAM, Score-CAM heatmap generation
  - `heatmap_metric.py` - Evaluate heatmap quality metrics
  - `runner.py` - Orchestrates visualization pipeline
- **Usage**: `python visualize.py model=resnet heatmap=gradcam`

#### `src/pipeline/` - Iterative Solver

- **Purpose**: Core optimization loop combining ML predictions with VRP solving
- **Key Files**:
  - `optimized_pipeline.py` - Main pipeline orchestrator
  - `arc_flagging.py` - ML-based arc penalty assignment
- **Usage**: Called by `iterative_solver.py` for full optimization

#### `MSH/` - Java VRP Solver

This part is based on the work of Nicolas Cabrera. It is where we implemnted the solver for one iteration
**Structure**

- bin : contains the compiled Java classes and dependencies
- config : contains configuration files for the solver (!Warning, if the config refers to a folder that hasn't been created yet, the output won't be produce)
- costs : contains cost-related files for the VRP
- instances : contains the VRP instances to be solved (i.e the coordinates files)
- output : contains the output files generated by the Gurobi solver 
- results : contains the results of the VRP instances. Each folder corresponds to one configuration
- src : contains the source code for the solver

#### `src/solver_results/` - Iterative solver Analysis and Visualization

- **Purpose**: Visualize the output of the iterative solver.
- **Key Files**:
  - `classification_analysis.py` - Analyzes classification results
  - `easy_classifier.py` - Implements a simplified classifier for quick testing
  - `first_valid_dataset.py` - Extracts the first valid dataset from results
  - `iteration_result.py` - Summarizes results from each iteration
  - `pca_analysis.py` - Performs PCA on the results for visualization
  - `results_dataset.py` - Prepares the results for dataset creation
  - `vrp_instance.py` - Loads the results (IterationResult) for one instance

#### `config/` - Hydra Configuration

- **Purpose**: Centralized configuration management for all components
- **Structure**:
  - `arcs/` - Arc-related configurations
  - `data/` - Data processing configurations
  - `heatmap/` - Heatmap generation configurations
  - `model/` - Model training and evaluation configurations
  - `plot/` - Plotting and visualization configurations
  - `solver/` - Solver-specific configurations
- **Usage**: Override with `python script.py model=resnet data.batch_size=32`

#### `src/graph/` - To plot the routes.

- **Key components**:
  - `graph_pipeline.py` - from the config in config/plot, generates the plots of the route, creates the mask difference bewteen the configuration1 and the other one then separate between training and testing set.
  - `mask.py` - Compute the difference between the same plot for different configurations.
  - `train_split.py` - Utilities for splitting training data
  - `graph_creator.py` - Plots the graphs from coordinates and arc file
  - `graph_flagging.py` - from a heatmap, creates txt files with the value of the heatmap along the arcs

## Quick Start

### Examples

Training

```bash
python train.py model=vgg batch_size=32 model_params.epochs=50
```

Visualization  

```bash
python visualize.py model=cnn heatmap.method=gradcam
```

### 1. Basic Usage

```python
from iterative_optimization import OptimizedVRPPipeline

# Initialize pipeline (loads model once)
pipeline = OptimizedVRPPipeline()

# Run iterative optimization
results = pipeline.iterative_optimization(
    instance_number=6,
    max_iterations=5,
    convergence_threshold=0.01
)

print(f"Best objective: {results['best_objective']}")
print(f"Converged: {results['converged']}")
```

### 2. Single Arc Flagging

```python
# Flag arcs without full optimization
flagged_arcs, flagged_coordinates = pipeline.flag_arcs(6, "1")
print(f"Flagged {len(flagged_arcs)} problematic arcs")
```

### 3. Custom Cost File Creation

```python
from custom_cost_integration import create_custom_cost_file_from_flagged_arcs

# Create custom cost file from flagged arcs
cost_file = create_custom_cost_file_from_flagged_arcs(
    flagged_arcs=flagged_arcs,
    instance_number=6,
    flagged_walking_multiplier=2.0,
    flagged_driving_multiplier=1.5
)
```

**Problem**: The original pipeline used a simple JAR execution command, but the VRP solver requires proper Gurobi integration.

**Solution**: Updated the `run_vrp_solver` method to use the correct Java command format:

```bash
java -Xmx14000m "-Djava.library.path=C:\gurobi1201\win64\bin" -cp "bin;C:\gurobi1201\win64\lib\gurobi.jar" main.Main_customCosts Coordinates_X.txt Arcs_X_1.txt configurationCustomCosts.xml
```

**Key Changes**:

- Proper Gurobi classpath and library path configuration
- Enhanced error reporting with stdout/stderr capture
- File validation checks for required inputs
- Support for different arc file suffixes

### Prerequisites

1. **Java 8+** with proper PATH configuration
2. **Gurobi Optimizer** (version 12.01) installed at `C:\gurobi1201\`
3. **Python 3.8+** with required packages:

   ```bash
   pip install torch torchvision matplotlib hydra-core
   ```

### Testing Java Integration

Before running the full pipeline, test the Java command integration:

```bash
python test_java_command.py
```

This will validate:

- All required files exist
- Gurobi installation paths are correct
- Java command executes properly
- Result parsing works correctly

## Testing

### Run All Tests

```bash
python test_iterative_optimization.py --test all
```

### Run Specific Tests

```bash
# Test single instance processing
python test_iterative_optimization.py --test single

# Test full iterative optimization
python test_iterative_optimization.py --test iterative

# Benchmark model loading performance
python test_iterative_optimization.py --test benchmark
```

### Adding a model

To add a new model to the pipeline, follow these steps:

1. **Implement the Model**: Create a new Python class for your model in the `src/models/` directory. Ensure it follows the same interface as existing models.

2. **Update Configuration**: Add a new entry for your model in the appropriate configuration files under `config/model/`.

3. **Integrate for training** : Add the training function to `src/trainers/` if needed, and ensure it can be called from `train.py`.
4. **Add heatmap methods**: If your model supports heatmaps, implement the necessary methods in `src/visualization/get_heatmap.py`.

### Running the solver

You have to make sure that you have gurobi installed and the path is set correctly in config.solver.java_lib.
The file `host.yaml` works for the cluster of Alliance Canada.

Then you can run

```bash
python iterative_solver.py [+overrides]
```

### MSH folder


