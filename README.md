# Optimized VRP Iterative Pipeline

This repository contains an optimized iterative pipeline that combines PyTorch-based arc flagging with Vehicle Routing Problem (VRP) solving. The main improvement is that the PyTorch model is loaded once and reused across iterations, signntly improving performance.

## Files Overview

### Core Pipeline Files

- `iterative_solver.py` - Main optimized pipeline class.
 - This files will run the iterative solver and return the csv files with the results of the iterations. In order for ir to work, you need to have the configuration1 arc files and the coordinates files existing. The .pth file referred in the config.model.weight_path must also exist.
- `train.py` - Function to train your computer vision model
- `visualize.py` - Function to see the output of your matrix.

- `run_vrp_solver.sh` - Shell script to run iterative VRP solver

### Java VRP Solver Integration

- `MSH/MSH/src/split/SplitWithEdgeConstraints.java` - Modified with custom cost calculation
- `MSH/MSH/src/distanceMatrices/CustomArcCostMatrix.java` - Custom cost storage
- `MSH/MSH/src/pulseStructures/PulseHandlerCC.java` - Pulse algorithm with custom costs

## Project Structure

### Core Modules

#### `src/models/` - Neural Network Models

- **Purpose**: PyTorch models for VRP image classification and segmentation
- **Key Files**:
  - `resnet.py` - ResNet-based classifier for arc scoring
  - `vgg_segment.py` - VGG model with segmentation head
  - `__init__.py` - Model factory and loading utilities
- **Usage**: Loaded once per pipeline run, reused across iterations

#### `src/trainers/` - Model Training

- **Purpose**: Training routines for VRP models
- **Key Files**:
  - `__init__.py` - Trainer factory and utilities
  
#### `src/visualization/` - Heatmap Generation

- **Purpose**: Generate and visualize heatmaps for model predictions. This is only used to visualize the heatmaps but the main script doesn't rely on this.
- **Key Files**:
  - `get_heatmap.py` - File where all the different heatmap methods are implemented
  - `save_overlay.py` - Saves overlay images of heatmaps on original images

- **Purpose**: Generate and overlay attention heatmaps on VRP instances
- **Key Files**:
  - `get_heatmap.py` - GradCAM, Score-CAM heatmap generation
  - `heatmap_metric.py` - Evaluate heatmap quality metrics
  - `runner.py` - Orchestrates visualization pipeline
- **Usage**: `python visualize.py model=resnet heatmap=gradcam`

#### `src/pipeline/` - Iterative Solver

- **Purpose**: Core optimization loop combining ML predictions with VRP solving
- **Key Files**:
  - `optimized_pipeline.py` - Main pipeline orchestrator
  - `arc_flagging.py` - ML-based arc penalty assignment
- **Usage**: Called by `iterative_solver.py` for full optimization

#### `MSH/` - Java VRP Solver

This part is based on the work of Nicolas Cabrera. It is where we implemnted the solver for one iteration
**Structure**

- bin : contains the compiled Java classes and dependencies
- config : contains configuration files for the solver (!Warning, if the config refers to a folder that hasn't been created yet, the output won't be produce)
- costs : contains cost-related files for the VRP
- instances : contains the VRP instances to be solved (i.e the coordinates files)
- output : contains the output files generated by the Gurobi solver 
- results : contains the results of the VRP instances. Each folder corresponds to one configuration
- src : contains the source code for the solver

#### `src/solver_results/` - Iterative solver Analysis and Visualization

- **Purpose**: Visualize the output of the iterative solver.
- **Key Files**:
  - `classification_analysis.py` - Analyzes classification results
  - `easy_classifier.py` - Implements a simplified classifier for quick testing
  - `first_valid_dataset.py` - Extracts the first valid dataset from results
  - `iteration_result.py` - Summarizes results from each iteration
  - `pca_analysis.py` - Performs PCA on the results for visualization
  - `results_dataset.py` - Prepares the results for dataset creation
  - `vrp_instance.py` - Loads the results (IterationResult) for one instance

#### `config/` - Hydra Configuration

- **Purpose**: Centralized configuration management for all components
- **Structure**:
  - `arcs/` - Arc-related configurations
  - `data/` - Data processing configurations
  - `heatmap/` - Heatmap generation configurations
  - `model/` - Model training and evaluation configurations
  - `plot/` - Plotting and visualization configurations
  - `solver/` - Solver-specific configurations
- **Usage**: Override with `python script.py model=resnet data.batch_size=32`

#### `src/graph/` - To plot the routes.

- **Key components**:
  - `graph_pipeline.py` - from the config in config/plot, generates the plots of the route, creates the mask difference bewteen the configuration1 and the other one then separate between training and testing set.
  - `mask.py` - Compute the difference between the same plot for different configurations.
  - `train_split.py` - Utilities for splitting training data
  - `graph_creator.py` - Plots the graphs from coordinates and arc file
  - `graph_flagging.py` - from a heatmap, creates txt files with the value of the heatmap along the arcs

## Quick Start

### Downloading the model

You can either train your own model, or reuse the one provided in this repo.
To download the pre-trained_model, run:

```bash
pip install huggingface-hub
python download_model.py
```

## Data
Although you could generate your own instances
You can unzip the Coordinates files from instances.zip in the MSH/MSH/instances folder. 
You can unzip the arcs files from results.zip in the MSH/MSH/results folder.

### Examples

Training

```bash
python train.py model=vgg batch_size=32 model_params.epochs=50
```

Visualization  

```bash
python visualize.py model=cnn heatmap.method=gradcam
```

### 1. Basic Usage

```python
from iterative_optimization import OptimizedVRPPipeline

# Initialize pipeline (loads model once)
pipeline = OptimizedVRPPipeline()

# Run iterative optimization
results = pipeline.iterative_optimization(
    instance_number=6,
    max_iterations=5,
    convergence_threshold=0.01
)

print(f"Best objective: {results['best_objective']}")
print(f"Converged: {results['converged']}")
```

### 2. Single Arc Flagging

```python
# Flag arcs without full optimization
flagged_arcs, flagged_coordinates = pipeline.flag_arcs(6, "1")
print(f"Flagged {len(flagged_arcs)} problematic arcs")
```

### 3. Custom Cost File Creation

```python
from custom_cost_integration import create_custom_cost_file_from_flagged_arcs

# Create custom cost file from flagged arcs
cost_file = create_custom_cost_file_from_flagged_arcs(
    flagged_arcs=flagged_arcs,
    instance_number=6,
    flagged_walking_multiplier=2.0,
    flagged_driving_multiplier=1.5
)
```

### Prerequisites

1. **Java 8+** with proper PATH configuration
2. **Gurobi Optimizer** (version 12.01) installed at `C:\gurobi1201\`
3. **Python 3.8+** with required packages:

   ```bash
   pip install -r requirements.txt
   ```


### Run All Tests

```bash
python test_iterative_optimization.py --test all
```

### Run Specific Tests

```bash
# Test single instance processing
python test_iterative_optimization.py --test single

# Test full iterative optimization
python test_iterative_optimization.py --test iterative

# Benchmark model loading performance
python test_iterative_optimization.py --test benchmark
```

### Adding a model

To add a new model to the pipeline, follow these steps:

1. **Implement the Model**: Create a new Python class for your model in the `src/models/` directory. Ensure it follows the same interface as existing models.

2. **Update Configuration**: Add a new entry for your model in the appropriate configuration files under `config/model/`.

3. **Integrate for training** : Add the training function to `src/trainers/` if needed, and ensure it can be called from `train.py`.
4. **Add heatmap methods**: If your model supports heatmaps, implement the necessary methods in `src/visualization/get_heatmap.py`.

### Running the solver

You have to make sure that you have gurobi installed and the path is set correctly in config.solver.java_lib.
The file `host.yaml` works for the cluster of Alliance Canada.

Then you can run

```bash
python iterative_solver.py [+overrides]
```
This will save in the output folder a folder containing csv files with the results of the iterations.

### MSH folder

The MSH folder contains the Java code for the PLRP solver. There are different main classes:
- CreateInstances.java: Creates the coordinates files in the instances/ folder
  - java main.CreateInstances maxX maxY numClients initialInstanceID finalInstanceID
  - This command will create the coordinates file from instance initialInstanceID to finalInstanceID with maxX and maxY as the maximum coordinates.
- Main_customCosts.java (NOT USED ANYMORE): This class refines a solution but with custom costs associated with the arcs. If no arc file is provided, it will only use the cost provided. Otherwise, it can also refine the solution based on the flagged arcs.
  - java main.CustomCosts coordinatesFile costFile config_file(.xml) arcsFile(can be None)
  - This command will create the custom costs files from instance initialInstanceID to finalInstanceID.
- Main_refineMSH.java: New version of Main_CustomCosts : it reruns a Sampling and Splitting for each route
- Main_Gurobi.java: This class creates a solution given a config file and a Coordinates file. It is the class used to create the configuration1.
  - java main.Main_Gurobi ExperimentsAllSets.txt instanceNumber config_file(.xml)
  - The ExperimentsAllSets.txt file simply contains for each row i the name "Coordinates_i.txt. I didn't modify the API.
- Main_refineEasy.java: Used to create configurationEasy. It simply stops walking loops before it gets too long.
- Main_refineUpperRightConstraint.java: Used to create configurationUpperRightConstraint. This is a version of the refiner that doesn't allow the walking route to go in the Upper Right corner of the map.
  - java main.Main_refineUpperRightConstraint coordinatesFile costFile config_file(.xml) arcsFile(can be None)
